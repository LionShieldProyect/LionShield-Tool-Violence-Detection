import cv2 as cv
import numpy as np
import os
import time
from action_classifier import ActionClassifier

# Mostrar el directorio actual
print(f"Directorio actual: {os.getcwd()}")

# Verificar si el archivo del modelo existe
model_path = "/Users/sebastiandevillasante/Desktop/Open_pose_video/Copia de graph_opt.pb 2"
print(f"Buscando el archivo: {model_path}")
if not os.path.exists(model_path):
    print(f"Error: No se encuentra el archivo {model_path}")
    exit(1)
else:
    print("¡Archivo encontrado!")

# Variables ajustables
width, height = 256, 256  # Reducido de 368x368 para mejor rendimiento
thr = 0.2  # Umbral más bajo para detectar más puntos

# Definir partes del cuerpo relevantes
BODY_PARTS = {
    "RShoulder": 2, "RElbow": 3, "RWrist": 4,
    "LShoulder": 5, "LElbow": 6, "LWrist": 7
}

# Cargar modelo
try:
    net = cv.dnn.readNetFromTensorflow(model_path)
    print("Modelo cargado exitosamente")
except cv.error as e:
    print(f"Error al cargar el modelo: {e}")
    exit(1)

# Inicializar el clasificador de acciones
action_classifier = ActionClassifier()

# Verificar si el modelo está entrenado
if not action_classifier.is_trained:
    print("ADVERTENCIA: El modelo no está entrenado. Por favor, ejecuta train_classifier.py primero.")
    print("Presiona 'q' para salir o cualquier otra tecla para continuar...")
    if cv.waitKey(0) & 0xFF == ord('q'):
        exit(1)

# Buffer para almacenar secuencias de keypoints
keypoint_buffer = []
MAX_BUFFER_SIZE = 10

# Detector de poses
def poseDetector(frame):
    global keypoint_buffer
    
    frameWidth, frameHeight = frame.shape[1], frame.shape[0]
    frame_small = cv.resize(frame, (width, height))
    
    net.setInput(cv.dnn.blobFromImage(frame_small, 1.0, (width, height), (127.5, 127.5, 127.5), swapRB=True, crop=False))
    out = net.forward()
    out = out[:, :19, :, :]
    
    if out.shape[1] != 19:
        print(f"Error: El modelo no está devolviendo el número correcto de puntos. Esperado: 19, Recibido: {out.shape[1]}")
        return frame

    people_points = []
    
    # Procesar puntos
    for i in range(19):
        if i not in BODY_PARTS.values():
            people_points.append([None])
            continue
            
        heatMap = out[0, i, :, :]
        heatMap = cv.resize(heatMap, (frameWidth, frameHeight))
        
        peaks = []
        heatMap_flat = heatMap.flatten()
        indices = np.where(heatMap_flat > thr * 0.5)[0]
        
        for idx in indices:
            y = idx // frameWidth
            x = idx % frameWidth
            
            if x > 0 and x < frameWidth-1 and y > 0 and y < frameHeight-1:
                if heatMap[y, x] >= heatMap[y-1:y+2, x-1:x+2].max():
                    peaks.append((x, y))
        
        if not peaks:
            peaks.append(None)
        people_points.append(peaks)
    
    # Preparar keypoints para el clasificador
    current_keypoints = []
    for part in BODY_PARTS.values():
        if people_points[part] and people_points[part][0] is not None:
            current_keypoints.append(people_points[part][0])
        else:
            current_keypoints.append((0, 0))
    
    # Actualizar buffer de keypoints
    keypoint_buffer.append(current_keypoints)
    if len(keypoint_buffer) > MAX_BUFFER_SIZE:
        keypoint_buffer.pop(0)
    
    # Si tenemos suficientes frames, usar el clasificador
    action = "neutra"
    confidence = 0.0
    
    if len(keypoint_buffer) == MAX_BUFFER_SIZE:
        try:
            action, confidence = action_classifier.predict(keypoint_buffer)
        except Exception as e:
            print(f"Error en la predicción: {e}")
    
    # Dibujar los keypoints
    for i, part in enumerate(BODY_PARTS.values()):
        if people_points[part] and people_points[part][0] is not None:
            point = people_points[part][0]
            cv.circle(frame, point, 3, (0, 255, 0), -1)
    
    # Mostrar la predicción en pantalla
    action_text = "Neutra"
    if action == "violencia":
        action_text = "Violencia"
    
    # Convertir confianza a porcentaje
    confidence_percent = confidence * 100
    
    # Dibujar fondo para el texto
    cv.rectangle(frame, (5, 5), (300, 40), (0, 0, 0), -1)
    
    # Mostrar texto con color según la acción
    color = (0, 255, 0)  # Verde para neutra
    if action == "violencia":
        color = (0, 0, 255)  # Rojo para violencia
    
    conf_text = f"Acción: {action_text} ({confidence_percent:.1f}%)"
    cv.putText(frame, conf_text, (10, 30), cv.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    
    return frame

# Inicializar la cámara
print("\nInicializando cámara...")
print("Intentando abrir la cámara con diferentes configuraciones...")

# Intentar diferentes configuraciones de cámara
camera_configs = [
    (0, cv.CAP_AVFOUNDATION),  # macOS
    (0, None),                 # Configuración por defecto
    (1, None),                 # Cámara secundaria
    (2, None)                  # Tercera cámara
]

cap = None
for camera_id, backend in camera_configs:
    try:
        if backend:
            cap = cv.VideoCapture(camera_id, backend)
        else:
            cap = cv.VideoCapture(camera_id)
        
        if cap.isOpened():
            print(f"✓ Cámara {camera_id} abierta exitosamente")
            
            # Configurar la resolución de la cámara
            cap.set(cv.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv.CAP_PROP_FPS, 30)
            
            # Verificar si la configuración se aplicó
            actual_width = cap.get(cv.CAP_PROP_FRAME_WIDTH)
            actual_height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)
            actual_fps = cap.get(cv.CAP_PROP_FPS)
            
            print(f"  - Resolución configurada: 640x480 (actual: {actual_width}x{actual_height})")
            print(f"  - FPS configurado: 30 (actual: {actual_fps})")
            
            # Intentar leer un frame para verificar
            ret, frame = cap.read()
            if ret:
                print("  - ✓ Lectura de frame exitosa")
                break
            else:
                print("  - ❌ No se pudo leer frame de la cámara")
                cap.release()
                cap = None
    except Exception as e:
        print(f"  - ❌ Error al abrir cámara {camera_id}: {e}")
        if cap:
            cap.release()
            cap = None

if not cap or not cap.isOpened():
    print("\n❌ No se pudo inicializar ninguna cámara")
    print("Por favor, verifica que:")
    print("1. La cámara está conectada")
    print("2. No hay otras aplicaciones usando la cámara")
    print("3. Tienes permisos para acceder a la cámara")
    exit(1)

print("\nIniciando detección de poses...")
print("Presiona 'q' para salir")

while True:
    ret, frame = cap.read()
    if not ret:
        print("❌ Error: No se pudo obtener un frame de la cámara")
        break

    # Voltear horizontalmente la imagen (para corregir el efecto espejo)
    frame = cv.flip(frame, 1)

    output = poseDetector(frame)
    cv.imshow("Detección de Poses", output)

    # Salir del bucle si se presiona la tecla 'q'
    if cv.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv.destroyAllWindows() 